{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward Scaling Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: All plots will be displayed in the figure below after running the subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03ad74caf55439d8f57b6b6162aa559",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAyAAAAIVCAYAAAApsJvCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5BklEQVR4nO3db2zd5Xk/4Nt28DGo2IRlcf7MNIOO0hZIaEI8QxFi8moJlC4vpnpQJVnEn9GmiMbaSkIgLqWNMwYoPxXTiBRGX5QlLQJUNVEY9RpVFE9Rk1iiIwHRQJNVtUnWYWehtYn9/b2o8GZyToiT+DnHh+uSzgs/PE/OfWPnPvmc7znHFVmWZQEAAJBAZbELAAAAPjwEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGACngpz/9aSxatChmzZoVFRUV8dxzz33gmR07dsSnP/3pyOVy8bGPfSyefPLJCa8ToFSZowDkI4AUcPTo0Zg7d250dnae1P433ngjbrjhhrjuuuuip6cnvvKVr8Qtt9wSzz///ARXClCazFEA8qnIsiwrdhGlrqKiIp599tlYvHhxwT133XVXbN26NX7xi1+Mrv3N3/xNvP3227F9+/YEVQKULnMUgPdMKXYB5aK7uzuam5vHrLW0tMRXvvKVgmcGBwdjcHBw9OuRkZH47W9/G3/0R38UFRUVE1Uq8CGWZVkcOXIkZs2aFZWVpXUR3BwFJoNSnqOThQByhvT29kZ9ff2Ytfr6+hgYGIjf/e53cfbZZx93pqOjI+67775UJQKMOnjwYPzJn/xJscsYwxwFJpNSnKOThQBSRKtXr462trbRr/v7++OCCy6IgwcPRm1tbRErA8rVwMBANDQ0xLnnnlvsUs4IcxRIrdzmaDEIIGfIjBkzoq+vb8xaX19f1NbW5n3WLiIil8tFLpc7br22ttYDJzChSvHlSeYoMJmU4hydLLxw7QxpamqKrq6uMWsvvPBCNDU1FakigMnFHAX4cBBACvif//mf6OnpiZ6enoj4w8dD9vT0xIEDByLiD5f9ly5dOrr/9ttvj/3798dXv/rV2LdvXzz66KPx/e9/P1auXFmM8gGKzhwFIB8BpICf//znccUVV8QVV1wRERFtbW1xxRVXxNq1ayMi4je/+c3og2hExJ/+6Z/G1q1b44UXXoi5c+fGQw89FN/5zneipaWlKPUDFJs5CkA+fg9ICRkYGIi6urro7+/32mVgQpT7nCn3/oDiM2dOnysgAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAByAp2dnTFnzpyoqamJxsbG2Llz5wn3b9iwIT7+8Y/H2WefHQ0NDbFy5cr4/e9/n6hagNJjjgLwfgJIAVu2bIm2trZob2+P3bt3x9y5c6OlpSXeeuutvPufeuqpWLVqVbS3t8fevXvj8ccfjy1btsTdd9+duHKA0mCOApCPAFLAww8/HLfeemssX748PvnJT8bGjRvjnHPOiSeeeCLv/pdeeimuvvrquOmmm2LOnDnx2c9+Nm688cYPfLYPoFyZowDkI4DkMTQ0FLt27Yrm5ubRtcrKymhubo7u7u68Z6666qrYtWvX6APl/v37Y9u2bXH99dcXvJ/BwcEYGBgYcwMoB+YoAIVMKXYBpejw4cMxPDwc9fX1Y9br6+tj3759ec/cdNNNcfjw4fjMZz4TWZbFsWPH4vbbbz/hSwc6OjrivvvuO6O1A5QCcxSAQlwBOUN27NgR69ati0cffTR2794dzzzzTGzdujXuv//+gmdWr14d/f39o7eDBw8mrBigtJijAB8OroDkMW3atKiqqoq+vr4x6319fTFjxoy8Z+69995YsmRJ3HLLLRERcdlll8XRo0fjtttuizVr1kRl5fFZL5fLRS6XO/MNABSZOQpAIa6A5FFdXR3z58+Prq6u0bWRkZHo6uqKpqamvGfeeeed4x4cq6qqIiIiy7KJKxagBJmjABTiCkgBbW1tsWzZsliwYEEsXLgwNmzYEEePHo3ly5dHRMTSpUtj9uzZ0dHRERERixYtiocffjiuuOKKaGxsjNdffz3uvffeWLRo0egDKMCHiTkKQD4CSAGtra1x6NChWLt2bfT29sa8efNi+/bto2+oPHDgwJhn6u65556oqKiIe+65J37961/HH//xH8eiRYvim9/8ZrFaACgqcxSAfCoy17VLxsDAQNTV1UV/f3/U1tYWuxygDJX7nCn3/oDiM2dOn/eAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgLICXR2dsacOXOipqYmGhsbY+fOnSfc//bbb8eKFSti5syZkcvl4uKLL45t27Ylqhag9JijALzflGIXUKq2bNkSbW1tsXHjxmhsbIwNGzZES0tLvPrqqzF9+vTj9g8NDcVf/uVfxvTp0+Ppp5+O2bNnx69+9as477zz0hcPUALMUQDyqciyLCt2EaWosbExrrzyynjkkUciImJkZCQaGhrijjvuiFWrVh23f+PGjfFP//RPsW/fvjjrrLNO6T4HBgairq4u+vv7o7a29rTqB8gn5ZwxR4FyZM6cPi/BymNoaCh27doVzc3No2uVlZXR3Nwc3d3dec/88Ic/jKamplixYkXU19fHpZdeGuvWrYvh4eGC9zM4OBgDAwNjbgDlwBwFoBABJI/Dhw/H8PBw1NfXj1mvr6+P3t7evGf2798fTz/9dAwPD8e2bdvi3nvvjYceeii+8Y1vFLyfjo6OqKurG701NDSc0T4AisUcBaAQAeQMGRkZienTp8djjz0W8+fPj9bW1lizZk1s3Lix4JnVq1dHf3//6O3gwYMJKwYoLeYowIeDN6HnMW3atKiqqoq+vr4x6319fTFjxoy8Z2bOnBlnnXVWVFVVja594hOfiN7e3hgaGorq6urjzuRyucjlcme2eIASYI4CUIgrIHlUV1fH/Pnzo6ura3RtZGQkurq6oqmpKe+Zq6++Ol5//fUYGRkZXXvttddi5syZeR80AcqZOQpAIQJIAW1tbbFp06b47ne/G3v37o0vfvGLcfTo0Vi+fHlERCxdujRWr149uv+LX/xi/Pa3v40777wzXnvttdi6dWusW7cuVqxYUawWAIrKHAUgHy/BKqC1tTUOHToUa9eujd7e3pg3b15s37599A2VBw4ciMrK/81vDQ0N8fzzz8fKlSvj8ssvj9mzZ8edd94Zd911V7FaACgqcxSAfPwekBLic6WBiVbuc6bc+wOKz5w5fV6CBQAAJCOAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgLICXR2dsacOXOipqYmGhsbY+fOnSd1bvPmzVFRURGLFy+e2AIBSpw5CsD7CSAFbNmyJdra2qK9vT12794dc+fOjZaWlnjrrbdOeO7NN9+Mv//7v49rrrkmUaUApckcBSAfAaSAhx9+OG699dZYvnx5fPKTn4yNGzfGOeecE0888UTBM8PDw/GFL3wh7rvvvrjwwgsTVgtQesxRAPIRQPIYGhqKXbt2RXNz8+haZWVlNDc3R3d3d8FzX//612P69Olx8803n9T9DA4OxsDAwJgbQDkwRwEoRADJ4/DhwzE8PBz19fVj1uvr66O3tzfvmRdffDEef/zx2LRp00nfT0dHR9TV1Y3eGhoaTqtugFJhjgJQiAByBhw5ciSWLFkSmzZtimnTpp30udWrV0d/f//o7eDBgxNYJUDpMkcBPjymFLuAUjRt2rSoqqqKvr6+Met9fX0xY8aM4/b/8pe/jDfffDMWLVo0ujYyMhIREVOmTIlXX301LrroouPO5XK5yOVyZ7h6gOIzRwEoxBWQPKqrq2P+/PnR1dU1ujYyMhJdXV3R1NR03P5LLrkkXn755ejp6Rm9fe5zn4vrrrsuenp6vCQA+NAxRwEoxBWQAtra2mLZsmWxYMGCWLhwYWzYsCGOHj0ay5cvj4iIpUuXxuzZs6OjoyNqamri0ksvHXP+vPPOi4g4bh3gw8IcBSAfAaSA1tbWOHToUKxduzZ6e3tj3rx5sX379tE3VB44cCAqK11AAijEHAUgn4osy7JiF8EfDAwMRF1dXfT390dtbW2xywHKULnPmXLvDyg+c+b0eeoJAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUBOoLOzM+bMmRM1NTXR2NgYO3fuLLh306ZNcc0118TUqVNj6tSp0dzcfML9AB8G5igA7yeAFLBly5Zoa2uL9vb22L17d8ydOzdaWlrirbfeyrt/x44dceONN8ZPfvKT6O7ujoaGhvjsZz8bv/71rxNXDlAazFEA8qnIsiwrdhGlqLGxMa688sp45JFHIiJiZGQkGhoa4o477ohVq1Z94Pnh4eGYOnVqPPLII7F06dKTus+BgYGoq6uL/v7+qK2tPa36AfJJOWfMUaAcmTOnzxWQPIaGhmLXrl3R3Nw8ulZZWRnNzc3R3d19Un/GO++8E++++26cf/75BfcMDg7GwMDAmBtAOTBHAShEAMnj8OHDMTw8HPX19WPW6+vro7e396T+jLvuuitmzZo15sH3/To6OqKurm701tDQcFp1A5QKcxSAQgSQCbB+/frYvHlzPPvss1FTU1Nw3+rVq6O/v3/0dvDgwYRVApQucxSgfE0pdgGlaNq0aVFVVRV9fX1j1vv6+mLGjBknPPvggw/G+vXr48c//nFcfvnlJ9yby+Uil8uddr0ApcYcBaAQV0DyqK6ujvnz50dXV9fo2sjISHR1dUVTU1PBcw888EDcf//9sX379liwYEGKUgFKkjkKQCGugBTQ1tYWy5YtiwULFsTChQtjw4YNcfTo0Vi+fHlERCxdujRmz54dHR0dERHxj//4j7F27dp46qmnYs6cOaOvcf7IRz4SH/nIR4rWB0CxmKMA5COAFNDa2hqHDh2KtWvXRm9vb8ybNy+2b98++obKAwcORGXl/15A+va3vx1DQ0Px13/912P+nPb29vja176WsnSAkmCOApCP3wNSQnyuNDDRyn3OlHt/QPGZM6fPe0AAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAeQEOjs7Y86cOVFTUxONjY2xc+fOE+7/wQ9+EJdccknU1NTEZZddFtu2bUtUKUBpMkcBeD8BpIAtW7ZEW1tbtLe3x+7du2Pu3LnR0tISb731Vt79L730Utx4441x8803x549e2Lx4sWxePHi+MUvfpG4coDSYI4CkE9FlmVZsYsoRY2NjXHllVfGI488EhERIyMj0dDQEHfccUesWrXquP2tra1x9OjR+NGPfjS69ud//ucxb9682Lhx40nd58DAQNTV1UV/f3/U1taemUYA/o+Uc8YcBcqROXP6phS7gFI0NDQUu3btitWrV4+uVVZWRnNzc3R3d+c9093dHW1tbWPWWlpa4rnnnit4P4ODgzE4ODj6dX9/f0T84QcbYCK8N18m+rkncxQoV6nmaDkTQPI4fPhwDA8PR319/Zj1+vr62LdvX94zvb29eff39vYWvJ+Ojo647777jltvaGg4haoBTt5//dd/RV1d3YT9+eYoUO4meo6WMwGkiFavXj3m2b633347PvrRj8aBAwfK8gd6YGAgGhoa4uDBg2V7ybLce9Tf5Nff3x8XXHBBnH/++cUu5Yz4sM3RiPL/OdXf5FfuPZbbHC0GASSPadOmRVVVVfT19Y1Z7+vrixkzZuQ9M2PGjHHtj4jI5XKRy+WOW6+rqyvLv7Dvqa2tLev+Isq/R/1NfpWVE/sZJOboxCv3n1P9TX7l3uNEz9Fy5v9cHtXV1TF//vzo6uoaXRsZGYmurq5oamrKe6apqWnM/oiIF154oeB+gHJmjgJQiCsgBbS1tcWyZctiwYIFsXDhwtiwYUMcPXo0li9fHhERS5cujdmzZ0dHR0dERNx5551x7bXXxkMPPRQ33HBDbN68OX7+85/HY489Vsw2AIrGHAUgHwGkgNbW1jh06FCsXbs2ent7Y968ebF9+/bRN0geOHBgzKW3q666Kp566qm455574u67744/+7M/i+eeey4uvfTSk77PXC4X7e3teV9OUA7Kvb+I8u9Rf5Nfyh7N0YlR7j3qb/Ir9x7Lvb8U/B4QAAAgGe8BAQAAkhFAAACAZAQQAAAgGQEEAABIRgBJrLOzM+bMmRM1NTXR2NgYO3fuPOH+H/zgB3HJJZdETU1NXHbZZbFt27ZElZ6a8fS3adOmuOaaa2Lq1KkxderUaG5u/sD/H6VgvN/D92zevDkqKipi8eLFE1vgaRpvf2+//XasWLEiZs6cGblcLi6++OKS/jkdb38bNmyIj3/843H22WdHQ0NDrFy5Mn7/+98nqnZ8fvrTn8aiRYti1qxZUVFREc8999wHntmxY0d8+tOfjlwuFx/72MfiySefnPA6T5c5+r/M0dJU7nM0wix9v8k4S4sqI5nNmzdn1dXV2RNPPJH9x3/8R3brrbdm5513XtbX15d3/89+9rOsqqoqe+CBB7JXXnklu+eee7Kzzjore/nllxNXfnLG299NN92UdXZ2Znv27Mn27t2b/e3f/m1WV1eX/ed//mfiyk/eeHt8zxtvvJHNnj07u+aaa7K/+qu/SlPsKRhvf4ODg9mCBQuy66+/PnvxxRezN954I9uxY0fW09OTuPKTM97+vve972W5XC773ve+l73xxhvZ888/n82cOTNbuXJl4spPzrZt27I1a9ZkzzzzTBYR2bPPPnvC/fv378/OOeecrK2tLXvllVeyb33rW1lVVVW2ffv2NAWfAnN0LHO09JT7HM0ys/T9JuMsLTYBJKGFCxdmK1asGP16eHg4mzVrVtbR0ZF3/+c///nshhtuGLPW2NiY/d3f/d2E1nmqxtvf+x07diw799xzs+9+97sTVeJpO5Uejx07ll111VXZd77znWzZsmUl/cA53v6+/e1vZxdeeGE2NDSUqsTTMt7+VqxYkf3FX/zFmLW2trbs6quvntA6z4STedD86le/mn3qU58as9ba2pq1tLRMYGWnxxw9MXO0+Mp9jmaZWfp+k3GWFpuXYCUyNDQUu3btiubm5tG1ysrKaG5uju7u7rxnuru7x+yPiGhpaSm4v5hOpb/3e+edd+Ldd9+N888/f6LKPC2n2uPXv/71mD59etx8880pyjxlp9LfD3/4w2hqaooVK1ZEfX19XHrppbFu3boYHh5OVfZJO5X+rrrqqti1a9foSwv2798f27Zti+uvvz5JzRNtMs2YCHP0ZJijxVXuczTCLM1nMs2ZUuE3oSdy+PDhGB4eHv0NwO+pr6+Pffv25T3T29ubd39vb++E1XmqTqW/97vrrrti1qxZx/0lLhWn0uOLL74Yjz/+ePT09CSo8PScSn/79++Pf/u3f4svfOELsW3btnj99dfjS1/6Urz77rvR3t6eouyTdir93XTTTXH48OH4zGc+E1mWxbFjx+L222+Pu+++O0XJE67QjBkYGIjf/e53cfbZZxepsvzM0Q9mjhZXuc/RCLM0n8k2S0uBKyCUhPXr18fmzZvj2WefjZqammKXc0YcOXIklixZEps2bYpp06YVu5wJMTIyEtOnT4/HHnss5s+fH62trbFmzZrYuHFjsUs7I3bs2BHr1q2LRx99NHbv3h3PPPNMbN26Ne6///5ilwbHMUcnp3KfoxFmKcdzBSSRadOmRVVVVfT19Y1Z7+vrixkzZuQ9M2PGjHHtL6ZT6e89Dz74YKxfvz5+/OMfx+WXXz6RZZ6W8fb4y1/+Mt58881YtGjR6NrIyEhEREyZMiVeffXVuOiiiya26HE4le/hzJkz46yzzoqqqqrRtU984hPR29sbQ0NDUV1dPaE1j8ep9HfvvffGkiVL4pZbbomIiMsuuyyOHj0at912W6xZsyYqKyf3cziFZkxtbW1JPmNnjhZmjpaGcp+jEWZpPpNtlpaCyf0dn0Sqq6tj/vz50dXVNbo2MjISXV1d0dTUlPdMU1PTmP0RES+88ELB/cV0Kv1FRDzwwANx//33x/bt22PBggUpSj1l4+3xkksuiZdffjl6enpGb5/73Ofiuuuui56enmhoaEhZ/gc6le/h1VdfHa+//vroPwgiIl577bWYOXNmyT1onkp/77zzznEPjO/9IyHLsokrNpHJNGMizNFCzNHSUe5zNMIszWcyzZmSUdz3wH+4bN68OcvlctmTTz6ZvfLKK9ltt92WnXfeeVlvb2+WZVm2ZMmSbNWqVaP7f/azn2VTpkzJHnzwwWzv3r1Ze3t7yX985Hj6W79+fVZdXZ09/fTT2W9+85vR25EjR4rVwgcab4/vV+qf3jLe/g4cOJCde+652Ze//OXs1VdfzX70ox9l06dPz77xjW8Uq4UTGm9/7e3t2bnnnpv9y7/8S7Z///7sX//1X7OLLroo+/znP1+sFk7oyJEj2Z49e7I9e/ZkEZE9/PDD2Z49e7Jf/epXWZZl2apVq7IlS5aM7n/voyP/4R/+Idu7d2/W2dlZ8h8daY6ao+Zo8Zmlk3+WFpsAkti3vvWt7IILLsiqq6uzhQsXZv/+7/8++t+uvfbabNmyZWP2f//7388uvvjirLq6OvvUpz6Vbd26NXHF4zOe/j760Y9mEXHcrb29PX3h4zDe7+H/VeoPnFk2/v5eeumlrLGxMcvlctmFF16YffOb38yOHTuWuOqTN57+3n333exrX/tadtFFF2U1NTVZQ0ND9qUvfSn77//+7/SFn4Sf/OQnef9OvdfTsmXLsmuvvfa4M/Pmzcuqq6uzCy+8MPvnf/7n5HWPlzm6bPRrc7Q0lfsczTKztBxmaTFVZFkZXPsCAAAmBe8BAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBpICf/vSnsWjRopg1a1ZUVFTEc88994FnduzYEZ/+9Kcjl8vFxz72sXjyyScnvE6AUmWOApCPAFLA0aNHY+7cudHZ2XlS+99444244YYb4rrrrouenp74yle+Erfccks8//zzE1wpQGkyRwHIpyLLsqzYRZS6ioqKePbZZ2Px4sUF99x1112xdevW+MUvfjG69jd/8zfx9ttvx/bt2xNUCVC6zFEA3uMKyBnS3d0dzc3NY9ZaWlqiu7u7SBUBTC7mKMCHw5RiF1Auent7o76+fsxafX19DAwMxO9+97s4++yzjzszODgYg4ODo1+PjIzEb3/72/ijP/qjqKiomPCagQ+fLMviyJEjMWvWrKisLK3noMxRYDIo5Tk6WQggRdTR0RH33XdfscsAPoQOHjwYf/Inf1LsMk6bOQoUS7nM0WIQQM6QGTNmRF9f35i1vr6+qK2tzfusXUTE6tWro62tbfTr/v7+uOCCC+LgwYNRW1s7ofUCH04DAwPR0NAQ5557brFLOY45CkwGpTxHJwsB5AxpamqKbdu2jVl74YUXoqmpqeCZXC4XuVzuuPXa2loPnMCEKsWXJ5mjwGRSinN0svDCtQL+53/+J3p6eqKnpyci/vDxkD09PXHgwIGI+MOzbkuXLh3df/vtt8f+/fvjq1/9auzbty8effTR+P73vx8rV64sRvkARWeOApCPAFLAz3/+87jiiiviiiuuiIiItra2uOKKK2Lt2rUREfGb3/xm9EE0IuJP//RPY+vWrfHCCy/E3Llz46GHHorvfOc70dLSUpT6AYrNHAUgH78HpIQMDAxEXV1d9Pf3e+kAMCHKfc6Ue39A8Zkzp88VEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFATqCzszPmzJkTNTU10djYGDt37jzh/g0bNsTHP/7xOPvss6OhoSFWrlwZv//97xNVC1B6zFEA3k8AKWDLli3R1tYW7e3tsXv37pg7d260tLTEW2+9lXf/U089FatWrYr29vbYu3dvPP7447Fly5a4++67E1cOUBrMUQDyEUAKePjhh+PWW2+N5cuXxyc/+cnYuHFjnHPOOfHEE0/k3f/SSy/F1VdfHTfddFPMmTMnPvvZz8aNN974gc/2AZQrcxSAfASQPIaGhmLXrl3R3Nw8ulZZWRnNzc3R3d2d98xVV10Vu3btGn2g3L9/f2zbti2uv/76gvczODgYAwMDY24A5cAcBaCQKcUuoBQdPnw4hoeHo76+fsx6fX197Nu3L++Zm266KQ4fPhyf+cxnIsuyOHbsWNx+++0nfOlAR0dH3HfffWe0doBSYI4CUIgrIGfIjh07Yt26dfHoo4/G7t2745lnnomtW7fG/fffX/DM6tWro7+/f/R28ODBhBUDlBZzFODDwRWQPKZNmxZVVVXR19c3Zr2vry9mzJiR98y9994bS5YsiVtuuSUiIi677LI4evRo3HbbbbFmzZqorDw+6+Vyucjlcme+AYAiM0cBKMQVkDyqq6tj/vz50dXVNbo2MjISXV1d0dTUlPfMO++8c9yDY1VVVUREZFk2ccUClCBzFIBCXAEpoK2tLZYtWxYLFiyIhQsXxoYNG+Lo0aOxfPnyiIhYunRpzJ49Ozo6OiIiYtGiRfHwww/HFVdcEY2NjfH666/HvffeG4sWLRp9AAX4MDFHAchHACmgtbU1Dh06FGvXro3e3t6YN29ebN++ffQNlQcOHBjzTN0999wTFRUVcc8998Svf/3r+OM//uNYtGhRfPOb3yxWCwBFZY4CkE9F5rp2yRgYGIi6urro7++P2traYpcDlKFynzPl3h9QfObM6fMeEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAOYHOzs6YM2dO1NTURGNjY+zcufOE+99+++1YsWJFzJw5M3K5XFx88cWxbdu2RNUClB5zFID3m1LsAkrVli1boq2tLTZu3BiNjY2xYcOGaGlpiVdffTWmT59+3P6hoaH4y7/8y5g+fXo8/fTTMXv27PjVr34V5513XvriAUqAOQpAPhVZlmXFLqIUNTY2xpVXXhmPPPJIRESMjIxEQ0ND3HHHHbFq1arj9m/cuDH+6Z/+Kfbt2xdnnXXWKd3nwMBA1NXVRX9/f9TW1p5W/QD5pJwz5ihQjsyZ0+clWHkMDQ3Frl27orm5eXStsrIympubo7u7O++ZH/7wh9HU1BQrVqyI+vr6uPTSS2PdunUxPDxc8H4GBwdjYGBgzA2gHJijABQigORx+PDhGB4ejvr6+jHr9fX10dvbm/fM/v374+mnn47h4eHYtm1b3HvvvfHQQw/FN77xjYL309HREXV1daO3hoaGM9oHQLGYowAUIoCcISMjIzF9+vR47LHHYv78+dHa2hpr1qyJjRs3FjyzevXq6O/vH70dPHgwYcUApcUcBfhw8Cb0PKZNmxZVVVXR19c3Zr2vry9mzJiR98zMmTPjrLPOiqqqqtG1T3ziE9Hb2xtDQ0NRXV193JlcLhe5XO7MFg9QAsxRAApxBSSP6urqmD9/fnR1dY2ujYyMRFdXVzQ1NeU9c/XVV8frr78eIyMjo2uvvfZazJw5M++DJkA5M0cBKEQAKaCtrS02bdoU3/3ud2Pv3r3xxS9+MY4ePRrLly+PiIilS5fG6tWrR/d/8YtfjN/+9rdx5513xmuvvRZbt26NdevWxYoVK4rVAkBRmaMA5OMlWAW0trbGoUOHYu3atdHb2xvz5s2L7du3j76h8sCBA1FZ+b/5raGhIZ5//vlYuXJlXH755TF79uy4884746677ipWCwBFZY4CkI/fA1JCfK40MNHKfc6Ue39A8Zkzp89LsAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkBBAAASEYAAQAAkhFAAACAZAQQAAAgGQEEAABIRgABAACSEUAAAIBkBBAAACAZAQQAAEhGAAEAAJIRQAAAgGQEEAAAIBkB5AQ6Oztjzpw5UVNTE42NjbFz586TOrd58+aoqKiIxYsXT2yBACXOHAXg/QSQArZs2RJtbW3R3t4eu3fvjrlz50ZLS0u89dZbJzz35ptvxt///d/HNddck6hSgNJkjgKQjwBSwMMPPxy33nprLF++PD75yU/Gxo0b45xzzoknnnii4Jnh4eH4whe+EPfdd19ceOGFCasFKD3mKAD5CCB5DA0Nxa5du6K5uXl0rbKyMpqbm6O7u7vgua9//esxffr0uPnmm1OUCVCyzFEACplS7AJK0eHDh2N4eDjq6+vHrNfX18e+ffvynnnxxRfj8ccfj56enpO+n8HBwRgcHBz9emBg4JTqBSg15igAhbgCcgYcOXIklixZEps2bYpp06ad9LmOjo6oq6sbvTU0NExglQClyxwF+PBwBSSPadOmRVVVVfT19Y1Z7+vrixkzZhy3/5e//GW8+eabsWjRotG1kZGRiIiYMmVKvPrqq3HRRRcdd2716tXR1tY2+vXAwIAHT6AsmKMAFCKA5FFdXR3z58+Prq6u0Y+AHBkZia6urvjyl7983P5LLrkkXn755TFr99xzTxw5ciT+3//7fwUfDHO5XORyuTNeP0CxmaMAFCKAFNDW1hbLli2LBQsWxMKFC2PDhg1x9OjRWL58eURELF26NGbPnh0dHR1RU1MTl1566Zjz5513XkTEcesAHxbmKAD5CCAFtLa2xqFDh2Lt2rXR29sb8+bNi+3bt4++ofLAgQNRWektNACFmKMA5FORZVlW7CL4g4GBgairq4v+/v6ora0tdjlAGSr3OVPu/QHFZ86cPk89AQAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAByAp2dnTFnzpyoqamJxsbG2LlzZ8G9mzZtimuuuSamTp0aU6dOjebm5hPuB/gwMEcBeD8BpIAtW7ZEW1tbtLe3x+7du2Pu3LnR0tISb731Vt79O3bsiBtvvDF+8pOfRHd3dzQ0NMRnP/vZ+PWvf524coDSYI4CkE9FlmVZsYsoRY2NjXHllVfGI488EhERIyMj0dDQEHfccUesWrXqA88PDw/H1KlT45FHHomlS5ee1H0ODAxEXV1d9Pf3R21t7WnVD5BPyjljjgLlyJw5fa6A5DE0NBS7du2K5ubm0bXKyspobm6O7u7uk/oz3nnnnXj33Xfj/PPPL7hncHAwBgYGxtwAyoE5CkAhAkgehw8fjuHh4aivrx+zXl9fH729vSf1Z9x1110xa9asMQ++79fR0RF1dXWjt4aGhtOqG6BUmKMAFCKATID169fH5s2b49lnn42ampqC+1avXh39/f2jt4MHDyasEqB0maMA5WtKsQsoRdOmTYuqqqro6+sbs97X1xczZsw44dkHH3ww1q9fHz/+8Y/j8ssvP+HeXC4XuVzutOsFKDXmKACFuAKSR3V1dcyfPz+6urpG10ZGRqKrqyuampoKnnvggQfi/vvvj+3bt8eCBQtSlApQksxRAApxBaSAtra2WLZsWSxYsCAWLlwYGzZsiKNHj8by5csjImLp0qUxe/bs6OjoiIiIf/zHf4y1a9fGU089FXPmzBl9jfNHPvKR+MhHPlK0PgCKxRwFIB8BpIDW1tY4dOhQrF27Nnp7e2PevHmxffv20TdUHjhwICor//cC0re//e0YGhqKv/7rvx7z57S3t8fXvva1lKUDlARzFIB8/B6QEuJzpYGJVu5zptz7A4rPnDl93gMCAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAn0NnZGXPmzImamppobGyMnTt3nnD/D37wg7jkkkuipqYmLrvssti2bVuiSgFKkzkKwPsJIAVs2bIl2traor29PXbv3h1z586NlpaWeOutt/Luf+mll+LGG2+Mm2++Ofbs2ROLFy+OxYsXxy9+8YvElQOUBnMUgHwqsizLil1EKWpsbIwrr7wyHnnkkYiIGBkZiYaGhrjjjjti1apVx+1vbW2No0ePxo9+9KPRtT//8z+PefPmxcaNG0/qPgcGBqKuri76+/ujtrb2zDQC8H+knDPmKFCOzJnTN6XYBZSioaGh2LVrV6xevXp0rbKyMpqbm6O7uzvvme7u7mhraxuz1tLSEs8991zB+xkcHIzBwcHRr/v7+yPiDz/YABPhvfky0c89maNAuUo1R8uZAJLH4cOHY3h4OOrr68es19fXx759+/Ke6e3tzbu/t7e34P10dHTEfffdd9x6Q0PDKVQNcPL+67/+K+rq6ibszzdHgXI30XO0nAkgRbR69eoxz/a9/fbb8dGPfjQOHDhQlj/QAwMD0dDQEAcPHizbS5bl3qP+Jr/+/v644IIL4vzzzy92KWfEh22ORpT/z6n+Jr9y77Hc5mgxCCB5TJs2LaqqqqKvr2/Mel9fX8yYMSPvmRkzZoxrf0RELpeLXC533HpdXV1Z/oV9T21tbVn3F1H+Pepv8qusnNjPIDFHJ165/5zqb/Ir9x4neo6WM//n8qiuro758+dHV1fX6NrIyEh0dXVFU1NT3jNNTU1j9kdEvPDCCwX3A5QzcxSAQlwBKaCtrS2WLVsWCxYsiIULF8aGDRvi6NGjsXz58oiIWLp0acyePTs6OjoiIuLOO++Ma6+9Nh566KG44YYbYvPmzfHzn/88HnvssWK2AVA05igA+QggBbS2tsahQ4di7dq10dvbG/PmzYvt27ePvkHywIEDYy69XXXVVfHUU0/FPffcE3fffXf82Z/9WTz33HNx6aWXnvR95nK5aG9vz/tygnJQ7v1FlH+P+pv8UvZojk6Mcu9Rf5NfufdY7v2l4PeAAAAAyXgPCAAAkIwAAgAAJCOAAAAAyQggAABAMgJIYp2dnTFnzpyoqamJxsbG2Llz5wn3/+AHP4hLLrkkampq4rLLLott27YlqvTUjKe/TZs2xTXXXBNTp06NqVOnRnNz8wf+/ygF4/0evmfz5s1RUVERixcvntgCT9N4+3v77bdjxYoVMXPmzMjlcnHxxReX9M/pePvbsGFDfPzjH4+zzz47GhoaYuXKlfH73/8+UbXj89Of/jQWLVoUs2bNioqKinjuuec+8MyOHTvi05/+dORyufjYxz4WTz755ITXebrM0f9ljpamcp+jEWbp+03GWVpUGcls3rw5q66uzp544onsP/7jP7Jbb701O++887K+vr68+3/2s59lVVVV2QMPPJC98sor2T333JOdddZZ2csvv5y48pMz3v5uuummrLOzM9uzZ0+2d+/e7G//9m+zurq67D//8z8TV37yxtvje954441s9uzZ2TXXXJP91V/9VZpiT8F4+xscHMwWLFiQXX/99dmLL76YvfHGG9mOHTuynp6exJWfnPH2973vfS/L5XLZ9773veyNN97Inn/++WzmzJnZypUrE1d+crZt25atWbMme+aZZ7KIyJ599tkT7t+/f392zjnnZG1tbdkrr7ySfetb38qqqqqy7du3pyn4FJijY5mjpafc52iWmaXvNxlnabEJIAktXLgwW7FixejXw8PD2axZs7KOjo68+z//+c9nN9xww5i1xsbG7O/+7u8mtM5TNd7+3u/YsWPZueeem333u9+dqBJP26n0eOzYseyqq67KvvOd72TLli0r6QfO8fb37W9/O7vwwguzoaGhVCWelvH2t2LFiuwv/uIvxqy1tbVlV1999YTWeSaczIPmV7/61exTn/rUmLXW1taspaVlAis7PeboiZmjxVfuczTLzNL3m4yztNi8BCuRoaGh2LVrVzQ3N4+uVVZWRnNzc3R3d+c9093dPWZ/RERLS0vB/cV0Kv293zvvvBPvvvtunH/++RNV5mk51R6//vWvx/Tp0+Pmm29OUeYpO5X+fvjDH0ZTU1OsWLEi6uvr49JLL41169bF8PBwqrJP2qn0d9VVV8WuXbtGX1qwf//+2LZtW1x//fVJap5ok2nGRJijJ8McLa5yn6MRZmk+k2nOlAq/CT2Rw4cPx/Dw8OhvAH5PfX197Nu3L++Z3t7evPt7e3snrM5TdSr9vd9dd90Vs2bNOu4vcak4lR5ffPHFePzxx6OnpydBhafnVPrbv39//Nu//Vt84QtfiG3btsXrr78eX/rSl+Ldd9+N9vb2FGWftFPp76abborDhw/HZz7zmciyLI4dOxa333573H333SlKnnCFZszAwED87ne/i7PPPrtIleVnjn4wc7S4yn2ORpil+Uy2WVoKXAGhJKxfvz42b94czz77bNTU1BS7nDPiyJEjsWTJkti0aVNMmzat2OVMiJGRkZg+fXo89thjMX/+/GhtbY01a9bExo0bi13aGbFjx45Yt25dPProo7F79+545plnYuvWrXH//fcXuzQ4jjk6OZX7HI0wSzmeKyCJTJs2LaqqqqKvr2/Mel9fX8yYMSPvmRkzZoxrfzGdSn/vefDBB2P9+vXx4x//OC6//PKJLPO0jLfHX/7yl/Hmm2/GokWLRtdGRkYiImLKlCnx6quvxkUXXTSxRY/DqXwPZ86cGWeddVZUVVWNrn3iE5+I3t7eGBoaiurq6gmteTxOpb977703lixZErfccktERFx22WVx9OjRuO2222LNmjVRWTm5n8MpNGNqa2tL8hk7c7Qwc7Q0lPscjTBL85lss7QUTO7v+CRSXV0d8+fPj66urtG1kZGR6OrqiqamprxnmpqaxuyPiHjhhRcK7i+mU+kvIuKBBx6I+++/P7Zv3x4LFixIUeopG2+Pl1xySbz88svR09Mzevvc5z4X1113XfT09ERDQ0PK8j/QqXwPr7766nj99ddH/0EQEfHaa6/FzJkzS+5B81T6e+edd457YHzvHwlZlk1csYlMphkTYY4WYo6WjnKfoxFmaT6Tac6UjOK+B/7DZfPmzVkul8uefPLJ7JVXXsluu+227Lzzzst6e3uzLMuyJUuWZKtWrRrd/7Of/SybMmVK9uCDD2Z79+7N2tvbS/7jI8fT3/r167Pq6urs6aefzn7zm9+M3o4cOVKsFj7QeHt8v1L/9Jbx9nfgwIHs3HPPzb785S9nr776avajH/0omz59evaNb3yjWC2c0Hj7a29vz84999zsX/7lX7L9+/dn//qv/5pddNFF2ec///litXBCR44cyfbs2ZPt2bMni4js4Ycfzvbs2ZP96le/yrIsy1atWpUtWbJkdP97Hx35D//wD9nevXuzzs7Okv/oSHPUHDVHi88snfyztNgEkMS+9a1vZRdccEFWXV2dLVy4MPv3f//30f927bXXZsuWLRuz//vf/3528cUXZ9XV1dmnPvWpbOvWrYkrHp/x9PfRj340i4jjbu3t7ekLH4fxfg//r1J/4Myy8ff30ksvZY2NjVkul8suvPDC7Jvf/GZ27NixxFWfvPH09+6772Zf+9rXsosuuiirqanJGhoasi996UvZf//3f6cv/CT85Cc/yft36r2eli1bll177bXHnZk3b15WXV2dXXjhhdk///M/J697vMzRZaNfm6OlqdznaJaZpeUwS4upIsvK4NoXAAAwKXgPCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkIwAAgAAJCOAAAAAyQggAABAMgIIAACQjAACAAAkI4AAAADJCCAAAEAyAggAAJCMAAIAACQjgAAAAMkIIAAAQDICCAAAkMz/B83f7wQ/vFEIAAAAAElFTkSuQmCC' width=800.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if \"reward_design_fig\" in locals():\n",
    "    plt.close(reward_design_fig)\n",
    "plt.ion()\n",
    "# reward_design_fig = plt.figure(figsize=[7, 4])\n",
    "# reward_design_ax = reward_design_fig.gca()\n",
    "reward_design_fig, reward_design_ax = plt.subplots(2, 2, figsize=[8, 16/3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyse Distance Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the distance-dependent reward function component $\\text{reward\\_fct\\_dist}(x)$, which for a given distance between end-effector and target $x$ returns the respective reward. \\\n",
    "Also, define the range $[\\text{xmin, xmax}]$ of distances that can be reached within an episode, as well as the maximum permissible distance to successfully reach/hit the target object $\\text{xeps}$ (for visualisation only). \\\n",
    "\\\n",
    "_Optional:_ Define the expected distance $\\text{xref}$ (for visualisation only).\n",
    "\n",
    "**Note:** For a more sophisticated distance reward design approach (using Cubic Splines to obtain a reward function that satisfies custom constraints), run cells in Section 1B instead and then continue with Section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define reward_fct_dist, xmin, xmax and xeps\n",
    "_alpha = 1/10\n",
    "reward_fct_dist = lambda x: (_alpha)*(np.exp(-(x/_alpha))-1)\n",
    "\n",
    "xmin = 0\n",
    "xmax = 0.5\n",
    "\n",
    "xeps = 0.025  #\"sufficient\" distance to fulfill the pointing task (typically, this corresponds to the target radius); often, if dist<=xeps (for the first time), an additional bonus reward is given\n",
    "xref = 0.3  #expected distance (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ymin, ymax, yeps and yref, as well as the x values to evaluate are automatically computed\n",
    "_ymin = reward_fct_dist(xmin)\n",
    "_ymax = reward_fct_dist(xmax)\n",
    "_yeps = reward_fct_dist(xeps)\n",
    "_yref = reward_fct_dist(xref)\n",
    "_xeval = np.linspace(xmin, xmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to fill the top left subplot in the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.sca(reward_design_ax[0, 0])\n",
    "plt.gca().clear()\n",
    "\n",
    "## plot reward function\n",
    "plt.plot(_xeval, reward_fct_dist(_xeval))\n",
    "\n",
    "## additionally plot chosen parameters\n",
    "_xlim_before = plt.gca().get_xlim()\n",
    "_ylim_before = plt.gca().get_ylim()\n",
    "xticks = plt.gca().get_xticks()\n",
    "# xticks = xticks[[0, -1]]\n",
    "xticks = xticks[xticks!=0]\n",
    "xticks_labels = xticks.tolist()\n",
    "yticks = plt.gca().get_yticks()\n",
    "# yticks = [yticks[-0], yticks[-1]]\n",
    "yticks_labels = yticks.tolist()\n",
    "\n",
    "plt.vlines(x=xeps, ymin=_ylim_before[0], ymax=_yeps, linestyle=\"--\", color=\"green\")\n",
    "xticks = np.append(xticks, xeps)\n",
    "xticks_labels.append(f\"$x_{{eps}}={xeps:.2f}$\")\n",
    "plt.hlines(y=_yeps, xmin=_xlim_before[0], xmax=xeps, linestyle=\"--\", color=\"green\")\n",
    "yticks = np.append(yticks, _yeps)\n",
    "yticks_labels.append(f\"$y_{{eps}}={_yeps:.2f}$\")\n",
    "\n",
    "plt.vlines(x=xmax, ymin=_ylim_before[0], ymax=_ymax, linestyle=\"--\", color=\"red\")\n",
    "xticks = np.append(xticks, xmax)\n",
    "xticks_labels.append(f\"$x_{{max}}={xmax:.2f}$\")\n",
    "plt.hlines(y=_ymax, xmin=_xlim_before[0], xmax=xmax, linestyle=\"--\", color=\"red\")\n",
    "yticks = np.append(yticks, _ymax)\n",
    "yticks_labels.append(f\"$y_{{max}}={_ymax:.2f}$\")\n",
    "\n",
    "plt.vlines(x=xref, ymin=_ylim_before[0], ymax=_yref, linestyle=\"--\", color=\"orange\")\n",
    "xticks = np.append(xticks, xref)\n",
    "xticks_labels.append(f\"$x_{{ref}}={xref:.2f}$\")\n",
    "plt.hlines(y=_yref, xmin=_xlim_before[0], xmax=xref, linestyle=\"--\", color=\"orange\")\n",
    "yticks = np.append(yticks, _yref)\n",
    "yticks_labels.append(f\"$y_{{ref}}={_yref:.2f}$\")\n",
    "\n",
    "_ticks_dict = dict(zip([np.round(i, 2) if isinstance(i, float) else i for i in xticks], xticks_labels))\n",
    "xticks, xticks_labels = list(_ticks_dict.keys()), [f\"{i:.2f}\" if isinstance(i, float) else i for i in _ticks_dict.values()]\n",
    "_ticks_dict = dict(zip([np.round(i, 2) if isinstance(i, float) else i for i in yticks], yticks_labels))\n",
    "yticks, yticks_labels = list(_ticks_dict.keys()), [f\"{i:.2f}\" if isinstance(i, float) else i for i in _ticks_dict.values()]\n",
    "\n",
    "plt.gca().set_xticks(xticks)\n",
    "plt.gca().set_xticklabels(xticks_labels)\n",
    "plt.gca().set_xlim(_xlim_before)\n",
    "plt.gca().set_yticks(yticks)\n",
    "plt.gca().set_yticklabels(yticks_labels)\n",
    "plt.gca().set_ylim(_ylim_before)\n",
    "# plt.gca().xaxis.set_major_formatter(plt.matplotlib.ticker.FormatStrFormatter('%.2f'))\n",
    "# plt.gca().yaxis.set_major_formatter(plt.matplotlib.ticker.FormatStrFormatter('%.2f'))\n",
    "# plt.gca().xaxis.set_major_locator(plt.matplotlib.ticker.AutoLocator()) #prune='lower'))\n",
    "# plt.gca().yaxis.set_major_locator(plt.matplotlib.ticker.AutoLocator()) #prune='lower'))\n",
    "\n",
    "## set xtick label colors\n",
    "[i.set_color(\"green\") if i._text.startswith(\"$x_{eps}\") else i.set_color(\"red\") if i._text.startswith(\"$x_{max}\") else i.set_color(\"orange\") if i._text.startswith(\"$x_{ref}\") else i for i in plt.gca().get_xticklabels() if \"$\" in i._text]\n",
    "[i.set_color(\"green\") if i._text.startswith(\"$y_{eps}\") else i.set_color(\"red\") if i._text.startswith(\"$y_{max}\") else i.set_color(\"orange\") if i._text.startswith(\"$y_{ref}\") else i for i in plt.gca().get_yticklabels() if \"$\" in i._text]\n",
    "\n",
    "plt.gca().set_xlabel(\"Distance\")\n",
    "plt.gca().set_ylabel(\"Reward $r$\")\n",
    "plt.gca().set_title(\"Distance Reward Function Design\", fontweight=\"bold\")\n",
    "\n",
    "# plt.gcf().autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimate Sequence of Distances During a Movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell allows to visualise the estimated distance reward during the course of a movement, for different scenarios. This is done as follows:\n",
    "* For learned, successful movements, the distance is assumed to decrease either linearly or quadratically over time (linear/quadratic interpolation between initial distance $\\text{xmax}$ and minimum distance $\\text{xmin}$).\n",
    "* In addition, the minimum and maximum distances $\\text{xmax}$ and $\\text{xmax}$, respectively, are plotted as constant lines, corresponding to (hypothetical) worst and best case scenarios (not moving towards the target at all / reaching the target instantaneously at the beginning of an episode).\n",
    "\n",
    "To this end, define the estimated duration per movement $\\text{estimated\\_duration\\_per\\_movement}$ (defines the x-axis scaling, and is later used for predicting trade-offs between reward function components), as well as the number of evaluation points $\\text{frame\\_rate}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_duration_per_movement = 1  #in seconds; defines time scaling of plot\n",
    "frame_rate = 20  #in Hz; defines number of evaluation points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to fill the top right subplot in the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.sca(reward_design_ax[0, 1])\n",
    "plt.gca().clear()\n",
    "\n",
    "# define times to evaluate reward at\n",
    "_time = np.linspace(0, estimated_duration_per_movement, estimated_duration_per_movement*frame_rate)\n",
    "\n",
    "# predict distances at evaluation times\n",
    "_reward_dists_lin = np.linspace(0, 1, estimated_duration_per_movement*frame_rate)\n",
    "_reward_dists_quad = 1-(1-_reward_dists_lin)**2\n",
    "\n",
    "## OPTIONAL: plot time scaling\n",
    "plt.gca().clear()\n",
    "plt.plot(_time, xmax + (xmin - xmax) * _reward_dists_lin)  #linear\n",
    "plt.plot(_time, xmax + (xmin - xmax) * _reward_dists_quad)  #quadratic\n",
    "plt.gca().set_xlabel(\"Time (s)\")\n",
    "plt.gca().set_ylabel(\"Distance\")\n",
    "\n",
    "# predict rewards at evaluation times\n",
    "_reward_vals_lin = reward_fct_dist(xmax + (xmin - xmax) * _reward_dists_lin)  #simplifying assumption: constant velocity\n",
    "_reward_vals_quad = reward_fct_dist(xmax + (xmin - xmax) * _reward_dists_quad)\n",
    "_reward_vals_worst = reward_fct_dist(xmax * np.ones_like(_reward_dists_lin))\n",
    "_reward_vals_best = reward_fct_dist(xmin * np.ones_like(_reward_dists_lin))\n",
    "\n",
    "## OPTIONAL: plot reward per time step\n",
    "plt.gca().clear()\n",
    "plt.scatter(_time, _reward_vals_lin, label=f\"linear dist. scaling ($\\sum r=${_reward_vals_lin.sum():2g})\")  #linear\n",
    "plt.scatter(_time, _reward_vals_quad, label=f\"quadratic dist. scaling ($\\sum r=${_reward_vals_quad.sum():2g})\")  #quadratic\n",
    "plt.scatter(_time, _reward_vals_worst, label=f\"worst case ($\\sum r=${_reward_vals_worst.sum():2g})\", s=10, alpha=0.4)  #worst case (assuming that initial distance = maximum distance)\n",
    "plt.scatter(_time, _reward_vals_best, label=f\"ideal case ($\\sum r=${_reward_vals_best.sum():2g})\", s=10, alpha=0.4)  #ideal case (not possible usually)\n",
    "plt.gca().set_xlabel(\"Time (s)\")\n",
    "plt.gca().set_ylabel(\"Reward $r$\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().set_title(\"Distance Reward Function Evaluation\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse Effort Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the control space by setting the control dimension $\\text{n\\_controls}$ (i.e., the number muscles/motor actuators) and the minimum and maximum control vectors $\\text{controlmin}$ and $\\text{controlmax}$ (each as numpy arrays of shape ($\\text{n\\_controls}$,)), respectively.\n",
    "\n",
    "You can also set $\\text{estimated\\_duration\\_per\\_movement}$ and $\\text{frame\\_rate}$, if you have not already done so above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_controls = 32  #control space dimension (number of muscles/motor actuators)\n",
    "## n_controls can also be directly inferred from a sample control series defined below:\n",
    "# n_controls = controls.iloc[0].shape[0]\n",
    "\n",
    "controlmin = 0 * np.ones(n_controls)  #minimum control value\n",
    "controlmax = 1 * np.ones(n_controls)  #maximum control value\n",
    "\n",
    "estimated_duration_per_movement = 1  #in seconds; defines time scaling of plot (and should be consistent with value set for distance reward plot above!)\n",
    "frame_rate = 20  #in Hz; defines number of evaluation points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the effort cost function by setting $\\text{effort\\_costs\\_class}(x)$ to one of the following effort models (originally implemented in UitB, re-implemented in `effort_models.py` as standalone classes that do not require loading a MuJoCo model):\n",
    "* $\\text{Neural\\_standalone}$\n",
    "* $\\text{CumulativeFatigue3CCr\\_standalone}$\n",
    "* $\\text{ConsumedEndurance\\_acts\\_standalone}$\n",
    "* _(or defining your own effort cost class in `effort_models.py`)_\n",
    "\n",
    "Also, define a control cost weight $\\text{effort\\_costs\\_weight}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requires uitb_tools to be installed as pip package\n",
    "from uitb_reward_scaling.effort_models import Neural_standalone, CumulativeFatigue3CCr_standalone, ConsumedEndurance_acts_standalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "effort_costs_class = Neural_standalone  #options: Neural_standalone, CumulativeFatigue3CCr_standalone, ConsumedEndurance_acts_standalone\n",
    "effort_costs_weight = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below allows to visualise the estimated effort during the course of a movement, for the following scenarios:\n",
    "* Min/Max/Mean: Assumes that the controls at each time step correspond to the minimum/maximum/(algebraic) mean of the manually defined control space.\n",
    "* Random: Assumes that the controls at each time step are uniformly random chosen from the manually defined control space _(stochastic simulation!)_.\n",
    "* Optimal: Apply controls as observed from an UitB simulation, e.g., using a policy trained with a first guess of the reward function to be defined. This requires loading logged UitB data, as shown below. (Warning: controls are still randomly sampled from the set of all loaded control vectors _(stochastic simulation!)_.)\n",
    "\n",
    "To this end, define the estimated duration per movement $\\text{estimated\\_duration\\_per\\_movement}$ (defines the x-axis scaling, and is later used for predicting trade-offs between reward function components), as well as the number of evaluation points $\\text{frame\\_rate}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load simulation controls and activations (used for \"optimal\" scenario)**\n",
    "\n",
    "The following cell loads controls and activations from sample data we have generated with the trained \"whacamole_constrained\" simulated user from the [SIM2VR paper](https://doi.org/10.1145/3654777.3676452).\n",
    " \n",
    "To use data logged from your own UitB simulation, set the simulation trajectory below using $\\text{dirname\\_simulation}$ and $\\text{dirname\\_simulation\\_run}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requires uitb_tools to be installed as pip package\n",
    "from uitb_evaluate.trajectory_data import TrajectoryData_RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 episodes identified.\n"
     ]
    }
   ],
   "source": [
    "dirname_simulation = \"sample_data/whacamole\"\n",
    "dirname_simulation_run = \"8501/21-28-53-medium\"\n",
    "\n",
    "trajectories_SIMULATION = TrajectoryData_RL(dirname_simulation, dirname_simulation_run)\n",
    "\n",
    "# TODO: update uitb_evaluate to ensure compatibility with SIM2VR simulation data (such that controls and activations can be directly computed by running trajectories_SIMULATION.preproces(), as originally intended)\n",
    "controls = pd.Series(list(trajectories_SIMULATION.data.values())[0][\"ctrl\"], index=pd.Index(list(trajectories_SIMULATION.data.values())[0][\"timestep\"], name=\"timestep\"), name=\"ctrl\")\n",
    "activations = pd.Series(list(trajectories_SIMULATION.data.values())[0][\"act\"], index=pd.Index(list(trajectories_SIMULATION.data.values())[0][\"timestep\"], name=\"timestep\"), name=\"act\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to fill the bottom left subplot in the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_effort_costs_instance = effort_costs_class(n_controls, dt=1/frame_rate, weight=effort_costs_weight)\n",
    "_effort_costs_fct = lambda i: (_effort_costs_instance.update(i), _effort_costs_instance.cost())[1]\n",
    "\n",
    "plt.sca(reward_design_ax[1, 0])\n",
    "plt.gca().clear()\n",
    "\n",
    "# define times to evaluate reward at\n",
    "_time = np.linspace(0, estimated_duration_per_movement, estimated_duration_per_movement*frame_rate)\n",
    "\n",
    "# predict rewards at evaluation times\n",
    "_effort_costs_instance.reset()\n",
    "_rng = np.random.default_rng()\n",
    "_effort_costs_random = np.array([_effort_costs_fct(_rng.uniform(low=controlmin, high=controlmax, size=n_controls)) for _ in range(len(_time))])\n",
    "_effort_costs_instance.reset()\n",
    "_effort_costs_mean = np.array([_effort_costs_fct(0.5*(controlmin + controlmax)) for _ in range(len(_time))])\n",
    "_effort_costs_instance.reset()\n",
    "_effort_costs_min = np.array([_effort_costs_fct(controlmin) for _ in range(len(_time))])\n",
    "_effort_costs_instance.reset()\n",
    "_effort_costs_max = np.array([_effort_costs_fct(controlmax) for _ in range(len(_time))])\n",
    "_effort_costs_instance.reset()\n",
    "# _effort_costs_optimal = np.array([_effort_costs_fct(np.vstack(controls.values).mean(axis=1)) for _ in range(len(_time))])\n",
    "_rng = np.random.default_rng()\n",
    "_effort_costs_optimal = np.array([_effort_costs_fct(_rng.choice(controls if effort_costs_class==Neural_standalone else activations)) for _ in range(len(_time))])\n",
    "\n",
    "## OPTIONAL: plot reward per time step\n",
    "plt.gca().clear()\n",
    "plt.scatter(_time, _effort_costs_random, label=f\"uniformly random ($\\sum r_e=${_effort_costs_random.sum():2g})\")  #uniformly random\n",
    "plt.scatter(_time, _effort_costs_optimal, label=f\"optimal ($\\sum r_e=${_effort_costs_optimal.sum():2g})\")  #controls selected by learned RL agent (not necessarily in this order!)\n",
    "plt.scatter(_time, _effort_costs_mean, label=f\"mean ($\\sum r_e=${_effort_costs_mean.sum():2g})\", s=10, alpha=0.4)  #mean activations\n",
    "plt.scatter(_time, _effort_costs_min, label=f\"min. ($\\sum r_e=${_effort_costs_min.sum():2g})\", s=10, alpha=0.4)  #zero activations\n",
    "plt.scatter(_time, _effort_costs_max, label=f\"max. ($\\sum r_e=${_effort_costs_max.sum():2g})\", s=10, alpha=0.4)  #maximum activations\n",
    "plt.gca().set_xlabel(\"Time (s)\")\n",
    "plt.gca().set_ylabel(\"Effort costs $r_e$\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().set_title(f\"Effort Cost Function Evaluation\\n{effort_costs_class.__name__.split('_standalone')[0]}\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot Total Rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the following cell, you can plot the total rewards (distance reward minus effort costs) over time, for different scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to fill the bottom right subplot in the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.sca(reward_design_ax[1, 1])\n",
    "plt.gca().clear()\n",
    "\n",
    "# define times to evaluate reward at\n",
    "_time = np.linspace(0, estimated_duration_per_movement, estimated_duration_per_movement*frame_rate)\n",
    "\n",
    "plt.gca().clear()\n",
    "plt.scatter(_time, _reward_vals_lin, label=f\"linear dist. scaling ($\\sum r=${_reward_vals_lin.sum():2g})\")  #linear\n",
    "plt.scatter(_time, _reward_vals_quad, label=f\"quadratic dist. scaling ($\\sum r=${_reward_vals_quad.sum():2g})\")  #quadratic\n",
    "plt.scatter(_time, _reward_vals_worst, label=f\"worst case ($\\sum r=${_reward_vals_worst.sum():2g})\", s=10, alpha=0.4)  #worst case (assuming that initial distance = maximum distance)\n",
    "plt.scatter(_time, _reward_vals_best, label=f\"ideal case ($\\sum r=${_reward_vals_best.sum():2g})\", s=10, alpha=0.4)  #ideal case (not possible usually)\n",
    "plt.gca().set_xlabel(\"Time (s)\")\n",
    "plt.gca().set_ylabel(\"Reward $r$\")\n",
    "\n",
    "## OPTIONAL: plot reward per time step\n",
    "plt.gca().clear()\n",
    "plt.scatter(_time, _reward_vals_quad - _effort_costs_random, label=f\"quadr. dist, random controls ($\\sum (r - r_e)=${(_reward_vals_quad-_effort_costs_random).sum():2g})\")  #quadr. time-to-distance mapping, random controls\n",
    "plt.scatter(_time, _reward_vals_quad - _effort_costs_optimal, label=f\"quadr. dist, optimal controls ($\\sum (r - r_e)=${(_reward_vals_quad-_effort_costs_optimal).sum():2g})\")  #quadr. time-to-distance mapping, controls selected by learned RL agent (not necessarily in this order!)\n",
    "plt.scatter(_time, _reward_vals_best - _effort_costs_max, label=f\"zero dist, max. controls ($\\sum (r - r_e)=${(_reward_vals_best-_effort_costs_max).sum():2g})\")  #maximum dist. reward, but maximum control costs\n",
    "plt.scatter(_time, _reward_vals_worst - _effort_costs_min, label=f\"max. dist, min. controls ($\\sum (r - r_e)=${(_reward_vals_worst-_effort_costs_min).sum():2g})\")  #maximum control costs, but minimum dist. reward\n",
    "plt.scatter(_time, _reward_vals_best - _effort_costs_min, label=f\"zero dist, min. controls ($\\sum (r - r_e)=${(_reward_vals_best-_effort_costs_min).sum():2g})\", s=10, alpha=0.4)  #maximum dist. reward and minimum control costs (optimum, if physically possible)\n",
    "plt.gca().set_xlabel(\"Time (s)\")\n",
    "plt.gca().set_ylabel(\"Total reward $r - r_e$\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().set_title(f\"Total Cost Function Evaluation\\n(Effort Costs: {effort_costs_class.__name__.split('_standalone')[0]})\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bonus Reward Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rule of thumb**: A one-time bonus reward given at time step $n_{\\text{early}}$ which results in early termination of an episode or at least in a target reset (i.e., it has a non-trivial effect on the total return per episode) needs to be chosen large enough to compensate for the opportunity cost of a longer lasting episode/target setup. This implies the following:\n",
    "1. If the bonus reward successfully terminates the episode, i.e., the regular reward achieved for the \"remaining\" time steps until the maximum number of steps $N$ is reached equals zero, the bonus needs to be larger than the opportunity cost of the maximum regular reward $r_{\\text{max}}$ that could have been achieved at each of these remaining time steps: \n",
    "$$r_{\\text{bonus}}\\geq\\sum_{i=n_{\\text{early}+1}}^{N}r_{\\text{max}}=(N-n_{\\text{early}})*r_{\\text{max}}$$\n",
    "\n",
    "2. If the success bonus does NOT terminate the episode but only resets the target, i.e., the regular reward for the \"remaining\" time steps until the maximum number of steps is reached can still be minimal, we need to take into account the difference between the maximum regular rewards that (hypothetically) could have been achieved at every remaining timestep (best-case continuing/non-bonus scenario) and the worst-case reward scenario that might be realized now instead (e.g., if the new target is spawned at maximum distance to the current position and the agent has no idea of how to get there): \n",
    "$$r_{\\text{bonus}}+\\sum_{i=n_{\\text{early}+1}}^{N}r_{\\text{min}}\\geq\\sum_{i=n_{\\text{early}+1}}^{N}r_{\\text{max}}\\\\\\Leftrightarrow r_{\\text{bonus}}\\geq\\sum_{i=n_{\\text{early}+1}}^{N}(r_{\\text{max}} - r_{\\text{min}})=(N-n_{\\text{early}})*(r_{\\text{max}} - r_{\\text{min}})$$\n",
    "\n",
    "In both cases, we can thus define the bonus term either depending on the remaining time, i.e., $r_{\\text{bonus}}(n_{\\text{early}})$, or, to be on the safe side, use $n_{\\text{early}}=0$ to obtain an upper bound for the minimum required bonus reward $r_{\\text{bonus}}$.\n",
    "For $n_{\\text{early}}=0$, the lower bounds can be derived from the values given in the legend of the bottom right plot in the above figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B. Appendix: Analyse Distance Reward with Cubic Splines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell allows to define an own dense distance reward function using cubic Hermite splines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax = 0.8  #initial/maximum distance that can be typically reached; used to scale entire reward term relative to other rewards\n",
    "_ymax = -0.1  #minimum negative reward; used to scale entire reward term relative to other rewards\n",
    "xeps = 0.025  #\"sufficient\" distance to fulfill the pointing task (typically, this corresponds to the target radius); often, if dist<=xeps (for the first time), an additional bonus reward is given\n",
    "_yeps = -0 #-0.05  #reward given at target boundary (WARNING: needs to be non-positive!); should be chosen between 10%*_ymax and _ymin=0\n",
    "xref = 0.3 #\"expected\" distance; used to scale gradients of this reward term appropriately\n",
    "_positive_only = True  #whether to ensure that all reward terms are positive (WARNING: requires that initial distance xmax is maximum reachable distance!)\n",
    "\n",
    "## Optional parameters:\n",
    "xmin = 0  #minimum distance\n",
    "_ymin = 0  #reward at target\n",
    "_dydxmin = 0  #reward gradient at target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell incorporates the assumptions on the values of the gradient of the distance reward function at nodes $\\text{xref}$, $\\text{xeps}$ and $\\text{xmax}$, as well as the distance reward at $\\text{xref}$.\n",
    "\n",
    "If $\\text{\\_positive\\_only} = \\text{True}$, the distance reward values at all nodes are adjusted to ensure non-negative distance rewards for any distances within the permitted range $[\\text{xmin, xmax}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dydxeps = (_yeps-_ymin)/(xeps-xmin)\n",
    "_dydxmax = 0.1*(_ymax-_ymin)/(xmax-xmin)  #initial reward gradient\n",
    "_alpha = (xref-xeps)/(xmax-xeps)  #0.5  #scale factor for linear interpolation between left secant (alpha=1) and right secant (alpha=0) -> if xref is closer to xeps, we need a more shallow gradient (i.e., alpha->0), if xref is closer to xmax, we need a steeper gradient (i.e., alpha->1) \n",
    "\n",
    "_yref = 0.5*(_ymin + _ymax)  #\"expected\"/\"average\" reward\n",
    "# _yref = _yeps + (_dydxmax-_dydxeps)*(_ymax-_yeps)  #\"expected\"/\"average\" reward\n",
    "# _yref = _yeps + (xref-xeps)/(xmax-xeps)*(_ymax-_yeps)  #\"expected\"/\"average\" reward\n",
    "\n",
    "_dydxref = _alpha*(_yref-_yeps)/(xref-xeps) + (1-_alpha)*(_ymax-_yref)/(xmax-xref) #-0.5  #\"expected\"/\"average\" reward gradient\n",
    "# _dydxref = (xmax-2*xref+xeps)*(_ymax-_yref)/(xmax-xref) #-0.5  #\"expected\"/\"average\" reward gradient\n",
    "\n",
    "assert _ymax <= 10*_yeps and _yeps <= _ymin, f\"'_yeps' should be chosen between 10%*_ymax={0.1*_ymax} and _ymin={_ymin}, but was set to _yeps={_yeps}.\"\n",
    "\n",
    "if _positive_only:\n",
    "    _ymin, _yeps, _yref, _ymax = (i-_ymax for i in (_ymin, _yeps, _yref, _ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = np.array([xmin, xeps, xref, xmax])\n",
    "_y = np.array([_ymin, _yeps, _yref, _ymax])\n",
    "_dydx = np.array([_dydxmin, _dydxeps, _dydxref, _dydxmax])\n",
    "\n",
    "_xeval = np.linspace(xmin, xmax)\n",
    "\n",
    "### DEFINE REWARD FUNCTION ###\n",
    "cs = scipy.interpolate.CubicHermiteSpline(x=_x, y=_y, dydx=_dydx)  #reward function r=cs(dist)\n",
    "reward_fct_dist = cs\n",
    "\n",
    "## check for invalid splines\n",
    "_spline_localmins_x = cs.derivative().roots()[np.logical_and.reduce((cs.derivative().derivative()(cs.derivative().roots()) > 0, xmin <= cs.derivative().roots(), cs.derivative().roots() <= xmax))]\n",
    "_spline_localmins_y = cs(_spline_localmins_x)\n",
    "if len(_spline_localmins_x) > 0:\n",
    "    print(f\"Invalid parameter choice! Reward function has local minima at (x={_spline_localmins_x}, y={_spline_localmins_y})!\")\n",
    "# _cs_test_fig = plt.figure()\n",
    "# _cs_test_fig.gca().scatter(_spline_localmins_x, _spline_localmins_y, s=100, marker=\"x\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to fill the top left subplot in the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.sca(reward_design_ax[0, 0])\n",
    "plt.gca().clear()\n",
    "\n",
    "## plot reward function\n",
    "plt.plot(_xeval, reward_fct_dist(_xeval))\n",
    "\n",
    "## additionally plot chosen parameters\n",
    "_xlim_before = plt.gca().get_xlim()\n",
    "_ylim_before = plt.gca().get_ylim()\n",
    "xticks = plt.gca().get_xticks()\n",
    "# xticks = xticks[[0, -1]]\n",
    "xticks = xticks[xticks!=0]\n",
    "xticks_labels = xticks.tolist()\n",
    "yticks = plt.gca().get_yticks()\n",
    "# yticks = [yticks[-0], yticks[-1]]\n",
    "yticks_labels = yticks.tolist()\n",
    "\n",
    "plt.vlines(x=xeps, ymin=_ylim_before[0], ymax=_yeps, linestyle=\"--\", color=\"green\")\n",
    "xticks = np.append(xticks, xeps)\n",
    "xticks_labels.append(f\"$x_{{eps}}={xeps:.2f}$\")\n",
    "plt.hlines(y=_yeps, xmin=_xlim_before[0], xmax=xeps, linestyle=\"--\", color=\"green\")\n",
    "yticks = np.append(yticks, _yeps)\n",
    "yticks_labels.append(f\"$y_{{eps}}={_yeps:.2f}$\")\n",
    "\n",
    "plt.vlines(x=xmax, ymin=_ylim_before[0], ymax=_ymax, linestyle=\"--\", color=\"red\")\n",
    "xticks = np.append(xticks, xmax)\n",
    "xticks_labels.append(f\"$x_{{max}}={xmax:.2f}$\")\n",
    "plt.hlines(y=_ymax, xmin=_xlim_before[0], xmax=xmax, linestyle=\"--\", color=\"red\")\n",
    "yticks = np.append(yticks, _ymax)\n",
    "yticks_labels.append(f\"$y_{{max}}={_ymax:.2f}$\")\n",
    "\n",
    "plt.vlines(x=xref, ymin=_ylim_before[0], ymax=_yref, linestyle=\"--\", color=\"orange\")\n",
    "xticks = np.append(xticks, xref)\n",
    "xticks_labels.append(f\"$x_{{ref}}={xref:.2f}$\")\n",
    "plt.hlines(y=_yref, xmin=_xlim_before[0], xmax=xref, linestyle=\"--\", color=\"orange\")\n",
    "yticks = np.append(yticks, _yref)\n",
    "yticks_labels.append(f\"$y_{{ref}}={_yref:.2f}$\")\n",
    "\n",
    "_ticks_dict = dict(zip([np.round(i, 2) if isinstance(i, float) else i for i in xticks], xticks_labels))\n",
    "xticks, xticks_labels = list(_ticks_dict.keys()), [f\"{i:.2f}\" if isinstance(i, float) else i for i in _ticks_dict.values()]\n",
    "_ticks_dict = dict(zip([np.round(i, 2) if isinstance(i, float) else i for i in yticks], yticks_labels))\n",
    "yticks, yticks_labels = list(_ticks_dict.keys()), [f\"{i:.2f}\" if isinstance(i, float) else i for i in _ticks_dict.values()]\n",
    "\n",
    "plt.gca().set_xticks(xticks)\n",
    "plt.gca().set_xticklabels(xticks_labels)\n",
    "plt.gca().set_xlim(_xlim_before)\n",
    "plt.gca().set_yticks(yticks)\n",
    "plt.gca().set_yticklabels(yticks_labels)\n",
    "plt.gca().set_ylim(_ylim_before)\n",
    "# plt.gca().xaxis.set_major_formatter(plt.matplotlib.ticker.FormatStrFormatter('%.2f'))\n",
    "# plt.gca().yaxis.set_major_formatter(plt.matplotlib.ticker.FormatStrFormatter('%.2f'))\n",
    "# plt.gca().xaxis.set_major_locator(plt.matplotlib.ticker.AutoLocator()) #prune='lower'))\n",
    "# plt.gca().yaxis.set_major_locator(plt.matplotlib.ticker.AutoLocator()) #prune='lower'))\n",
    "\n",
    "## set xtick label colors\n",
    "[i.set_color(\"green\") if i._text.startswith(\"$x_{eps}\") else i.set_color(\"red\") if i._text.startswith(\"$x_{max}\") else i.set_color(\"orange\") if i._text.startswith(\"$x_{ref}\") else i for i in plt.gca().get_xticklabels() if \"$\" in i._text]\n",
    "[i.set_color(\"green\") if i._text.startswith(\"$y_{eps}\") else i.set_color(\"red\") if i._text.startswith(\"$y_{max}\") else i.set_color(\"orange\") if i._text.startswith(\"$y_{ref}\") else i for i in plt.gca().get_yticklabels() if \"$\" in i._text]\n",
    "\n",
    "plt.gca().set_xlabel(\"Distance\")\n",
    "plt.gca().set_ylabel(\"Reward $r$\")\n",
    "plt.gca().set_title(\"Distance Reward Function Design\", fontweight=\"bold\")\n",
    "\n",
    "# plt.gcf().autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uitb_gymnasium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
